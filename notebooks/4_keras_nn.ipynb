{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 970 (CNMeM is enabled with initial size: 75.0% of memory, cuDNN 4007)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import theano\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.regularizers import l2, activity_l2\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read in data week 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors_target_10 = ['agen_for_log_de', 'ruta_for_log_de', 'cliente_for_log_de',\n",
    "       'producto_for_log_de', 'agen_ruta_for_log_de',\n",
    "       'agen_cliente_for_log_de', 'agen_producto_for_log_de',\n",
    "       'ruta_cliente_for_log_de', 'ruta_producto_for_log_de',\n",
    "       'cliente_producto_for_log_de', 'cliente_for_log_sum', 'corr',\n",
    "       't_min_1', 't_min_2', 't_min_3', 't_min_4', 't_min_5', 't1_min_t2',\n",
    "       't1_min_t3', 't1_min_t4', 't1_min_t5', 't2_min_t3', 't2_min_t4',\n",
    "       't2_min_t5', 't3_min_t4', 't3_min_t5', 't4_min_t5', 'LR_prod',\n",
    "       'LR_prod_corr', 't_m_5_cum', 't_m_4_cum', 't_m_3_cum',\n",
    "       't_m_2_cum', 't_m_1_cum', 'NombreCliente', 'weight',\n",
    "       'weight_per_piece', 'pieces','target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors_10 = ['agen_for_log_de', 'ruta_for_log_de', 'cliente_for_log_de',\n",
    "       'producto_for_log_de', 'agen_ruta_for_log_de',\n",
    "       'agen_cliente_for_log_de', 'agen_producto_for_log_de',\n",
    "       'ruta_cliente_for_log_de', 'ruta_producto_for_log_de',\n",
    "       'cliente_producto_for_log_de', 'cliente_for_log_sum', 'corr',\n",
    "       't_min_1', 't_min_2', 't_min_3', 't_min_4', 't_min_5', 't1_min_t2',\n",
    "       't1_min_t3', 't1_min_t4', 't1_min_t5', 't2_min_t3', 't2_min_t4',\n",
    "       't2_min_t5', 't3_min_t4', 't3_min_t5', 't4_min_t5', 'LR_prod',\n",
    "       'LR_prod_corr', 't_m_5_cum', 't_m_4_cum', 't_m_3_cum',\n",
    "       't_m_2_cum', 't_m_1_cum', 'NombreCliente', 'weight',\n",
    "       'weight_per_piece', 'pieces']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtypes = {'agen_for_log_de':'float32',\n",
    "        'ruta_for_log_de':'float32',\n",
    "        'cliente_for_log_de':'float32',\n",
    "        'producto_for_log_de':'float32',\n",
    "        'agen_ruta_for_log_de':'float32',\n",
    "        'agen_cliente_for_log_de':'float32',\n",
    "        'agen_producto_for_log_de':'float32',\n",
    "        'ruta_cliente_for_log_de':'float32',\n",
    "        'ruta_producto_for_log_de':\"float32\",\n",
    "        'cliente_producto_for_log_de':'float32',\n",
    "        'cliente_for_log_sum':'float32',\n",
    "        'corr':'float32',\n",
    "        't_min_1':'float32',\n",
    "        't_min_2':'float32',\n",
    "        't_min_3':'float32',\n",
    "        't_min_4':'float32',\n",
    "        't_min_5':'float32',\n",
    "        't1_min_t2':'float32',\n",
    "        't1_min_t3':'float32',\n",
    "        't1_min_t4':'float32',\n",
    "        't1_min_t5':'float32',\n",
    "        't2_min_t3':'float32',\n",
    "        't2_min_t4':'float32',\n",
    "        't2_min_t5':'float32',\n",
    "        't3_min_t4':'float32',\n",
    "        't3_min_t5':'float32',\n",
    "        't4_min_t5':'float32',\n",
    "        'LR_prod':'float32',\n",
    "        'LR_prod_corr':'float32',\n",
    "        'target':'float32',\n",
    "        't_m_5_cum':'float32',\n",
    "        't_m_4_cum' :'float32',\n",
    "        't_m_3_cum':'float32',\n",
    "        't_m_2_cum':'float32',\n",
    "        't_m_1_cum':'float32',\n",
    "        'NombreCliente':'int32',\n",
    "        'weight':'float32',\n",
    "        'weight_per_piece':'float32',\n",
    "        'pieces':'float32'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = lambda x : (x-x.mean())/x.std(ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_dataset_10(train_dataset,test_dataset):\n",
    "    train_dataset_normalize = train_dataset[predictors_10]\n",
    "    train_dataset_normalize['label'] = 0    \n",
    "    \n",
    "    test_dataset_normalize = test_dataset[predictors_10]\n",
    "    test_dataset_normalize['label'] = 1\n",
    "    \n",
    "    whole_dataset = pd.concat([train_dataset_normalize,test_dataset_normalize],copy = False)\n",
    "    whole_dataset_normalize = whole_dataset.apply(f,axis = 0)\n",
    "    \n",
    "    train_dataset_normalize = whole_dataset_normalize.loc[whole_dataset['label'] == 0]\n",
    "    test_dataset_normalize = whole_dataset_normalize.loc[whole_dataset['label']==1]\n",
    "    \n",
    "    train_dataset_normalize.drop(['label'],axis = 1,inplace = True)\n",
    "    test_dataset_normalize.drop(['label'],axis =1,inplace = True)\n",
    "    \n",
    "    train_dataset_normalize['target'] = train_dataset['target']\n",
    "    \n",
    "#     target = train_dataset['target']\n",
    "    return train_dataset_normalize,test_dataset_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pivot_xgb_time1 = pd.read_csv('train_pivot_xgb_time1.csv',\n",
    "                                    usecols = predictors_target_10,dtype = dtypes)\n",
    "train_pivot_xgb_time1.reset_index(drop = True,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pivot_56789_to_10 = pd.read_pickle('train_pivot_56789_to_10_new.pickle')\n",
    "train_pivot_56789_to_10.reset_index(drop = True,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "train_dataset_10_normalize, test_dataset_10_normalize = normalize_dataset_10(train_pivot_xgb_time1,\n",
    "                                                                          train_pivot_56789_to_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_pivot_xgb_time1 = train_pivot_xgb_time1.sample(1000) \n",
    "# train_pivot_xgb_time1.reset_index(drop = True,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create nn train data for model stacking\n",
    "-----------------------------\n",
    "- 5 fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset_10_normalize.fillna(-1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_fold = cross_validation.KFold(n=train_dataset_10_normalize.shape[0], n_folds=5)\n",
    "\n",
    "a = np.zeros(shape=(train_dataset_10_normalize.shape[0],1))\n",
    "stack_submission_nn_10 = pd.DataFrame(a,columns=['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "93s - loss: 0.2085\n",
      "Epoch 2/100\n",
      "93s - loss: 0.2031\n",
      "Epoch 3/100\n",
      "93s - loss: 0.2020\n",
      "Epoch 4/100\n",
      "93s - loss: 0.2015\n",
      "Epoch 5/100\n",
      "93s - loss: 0.2011\n",
      "Epoch 6/100\n",
      "93s - loss: 0.2009\n",
      "Epoch 7/100\n",
      "93s - loss: 0.2007\n",
      "Epoch 8/100\n",
      "93s - loss: 0.2005\n",
      "Epoch 9/100\n",
      "93s - loss: 0.2003\n",
      "Epoch 10/100\n",
      "93s - loss: 0.2002\n",
      "Epoch 11/100\n",
      "93s - loss: 0.2001\n",
      "Epoch 12/100\n",
      "92s - loss: 0.2000\n",
      "Epoch 13/100\n",
      "92s - loss: 0.2000\n",
      "Epoch 14/100\n",
      "92s - loss: 0.1998\n",
      "Epoch 15/100\n",
      "92s - loss: 0.1998\n",
      "Epoch 16/100\n",
      "92s - loss: 0.1997\n",
      "Epoch 17/100\n",
      "92s - loss: 0.1997\n",
      "Epoch 18/100\n",
      "92s - loss: 0.1997\n",
      "Epoch 19/100\n",
      "92s - loss: 0.1996\n",
      "Epoch 20/100\n",
      "92s - loss: 0.1995\n",
      "Epoch 21/100\n",
      "92s - loss: 0.1995\n",
      "Epoch 22/100\n",
      "92s - loss: 0.1995\n",
      "Epoch 23/100\n",
      "92s - loss: 0.1994\n",
      "Epoch 24/100\n",
      "92s - loss: 0.1994\n",
      "Epoch 25/100\n",
      "92s - loss: 0.1994\n",
      "Epoch 26/100\n",
      "92s - loss: 0.1994\n",
      "Epoch 27/100\n",
      "92s - loss: 0.1993\n",
      "Epoch 28/100\n",
      "92s - loss: 0.1993\n",
      "Epoch 29/100\n",
      "92s - loss: 0.1993\n",
      "Epoch 30/100\n",
      "92s - loss: 0.1993\n",
      "Epoch 31/100\n",
      "92s - loss: 0.1992\n",
      "Epoch 32/100\n",
      "92s - loss: 0.1992\n",
      "Epoch 33/100\n",
      "92s - loss: 0.1992\n",
      "Epoch 34/100\n",
      "92s - loss: 0.1992\n",
      "Epoch 35/100\n",
      "92s - loss: 0.1992\n",
      "Epoch 36/100\n",
      "92s - loss: 0.1992\n",
      "Epoch 37/100\n",
      "92s - loss: 0.1992\n",
      "Epoch 38/100\n",
      "92s - loss: 0.1991\n",
      "Epoch 39/100\n",
      "92s - loss: 0.1991\n",
      "Epoch 40/100\n",
      "92s - loss: 0.1991\n",
      "Epoch 41/100\n",
      "92s - loss: 0.1991\n",
      "Epoch 42/100\n",
      "92s - loss: 0.1991\n",
      "Epoch 43/100\n",
      "92s - loss: 0.1991\n",
      "Epoch 44/100\n",
      "92s - loss: 0.1991\n",
      "Epoch 45/100\n",
      "92s - loss: 0.1991\n",
      "Epoch 46/100\n",
      "92s - loss: 0.1991\n",
      "Epoch 47/100\n",
      "92s - loss: 0.1991\n",
      "Epoch 48/100\n",
      "92s - loss: 0.1991\n",
      "Epoch 49/100\n",
      "92s - loss: 0.1991\n",
      "Epoch 50/100\n",
      "92s - loss: 0.1990\n",
      "Epoch 51/100\n",
      "92s - loss: 0.1990\n",
      "Epoch 52/100\n",
      "92s - loss: 0.1990\n",
      "Epoch 53/100\n",
      "92s - loss: 0.1990\n",
      "Epoch 54/100\n",
      "92s - loss: 0.1990\n",
      "Epoch 55/100\n",
      "92s - loss: 0.1990\n",
      "Epoch 56/100\n",
      "92s - loss: 0.1990\n",
      "Epoch 57/100\n",
      "92s - loss: 0.1990\n",
      "Epoch 58/100\n",
      "92s - loss: 0.1990\n",
      "Epoch 59/100\n",
      "92s - loss: 0.1990\n",
      "Epoch 60/100\n",
      "92s - loss: 0.1990\n",
      "Epoch 61/100\n",
      "92s - loss: 0.1990\n",
      "Epoch 62/100\n",
      "92s - loss: 0.1990\n",
      "Epoch 63/100\n",
      "92s - loss: 0.1989\n",
      "Epoch 64/100\n",
      "92s - loss: 0.1990\n",
      "Epoch 65/100\n",
      "92s - loss: 0.1989\n",
      "Epoch 66/100\n",
      "92s - loss: 0.1989\n",
      "Epoch 67/100\n",
      "92s - loss: 0.1989\n",
      "Epoch 68/100\n",
      "92s - loss: 0.1989\n",
      "Epoch 69/100\n",
      "92s - loss: 0.1989\n",
      "Epoch 70/100\n",
      "92s - loss: 0.1989\n",
      "Epoch 71/100\n",
      "92s - loss: 0.1989\n",
      "Epoch 72/100\n",
      "92s - loss: 0.1989\n",
      "Epoch 73/100\n",
      "92s - loss: 0.1989\n",
      "Epoch 74/100\n",
      "92s - loss: 0.1989\n",
      "Epoch 75/100\n",
      "92s - loss: 0.1989\n",
      "Epoch 76/100\n",
      "92s - loss: 0.1989\n",
      "Epoch 77/100\n",
      "92s - loss: 0.1989\n",
      "Epoch 78/100\n",
      "92s - loss: 0.1989\n",
      "Epoch 79/100\n",
      "92s - loss: 0.1989\n",
      "Epoch 80/100\n",
      "92s - loss: 0.1989\n",
      "Epoch 81/100\n",
      "92s - loss: 0.1989\n",
      "Epoch 82/100\n",
      "92s - loss: 0.1989\n",
      "Epoch 83/100\n",
      "92s - loss: 0.1989\n",
      "Epoch 84/100\n",
      "92s - loss: 0.1989\n",
      "Epoch 85/100\n",
      "92s - loss: 0.1989\n",
      "Epoch 86/100\n",
      "92s - loss: 0.1989\n",
      "Epoch 87/100\n",
      "92s - loss: 0.1989\n",
      "Epoch 88/100\n",
      "92s - loss: 0.1989\n",
      "Epoch 89/100\n",
      "92s - loss: 0.1989\n",
      "Epoch 90/100\n",
      "92s - loss: 0.1988\n",
      "Epoch 91/100\n",
      "92s - loss: 0.1989\n",
      "Epoch 92/100\n",
      "92s - loss: 0.1989\n",
      "Epoch 93/100\n",
      "92s - loss: 0.1988\n",
      "Epoch 94/100\n",
      "92s - loss: 0.1988\n",
      "Epoch 95/100\n",
      "92s - loss: 0.1988\n",
      "Epoch 96/100\n",
      "92s - loss: 0.1988\n",
      "Epoch 97/100\n",
      "92s - loss: 0.1988\n",
      "Epoch 98/100\n",
      "92s - loss: 0.1988\n",
      "Epoch 99/100\n",
      "92s - loss: 0.1988\n",
      "Epoch 100/100\n",
      "92s - loss: 0.1988\n",
      "model fit finished\n",
      "model predict finished\n",
      "Epoch 1/100\n",
      "91s - loss: 0.2076\n",
      "Epoch 2/100\n",
      "91s - loss: 0.2024\n",
      "Epoch 3/100\n",
      "92s - loss: 0.2011\n",
      "Epoch 4/100\n",
      "92s - loss: 0.2005\n",
      "Epoch 5/100\n",
      "92s - loss: 0.2002\n",
      "Epoch 6/100\n",
      "92s - loss: 0.2000\n",
      "Epoch 7/100\n",
      "92s - loss: 0.1998\n",
      "Epoch 8/100\n",
      "92s - loss: 0.1996\n",
      "Epoch 9/100\n",
      "92s - loss: 0.1995\n",
      "Epoch 10/100\n",
      "92s - loss: 0.1994\n",
      "Epoch 11/100\n",
      "92s - loss: 0.1993\n",
      "Epoch 12/100\n",
      "92s - loss: 0.1992\n",
      "Epoch 13/100\n",
      "92s - loss: 0.1991\n",
      "Epoch 14/100\n",
      "93s - loss: 0.1991\n",
      "Epoch 15/100\n",
      "93s - loss: 0.1990\n",
      "Epoch 16/100\n",
      "93s - loss: 0.1990\n",
      "Epoch 17/100\n",
      "93s - loss: 0.1989\n",
      "Epoch 18/100\n",
      "92s - loss: 0.1989\n",
      "Epoch 19/100\n",
      "92s - loss: 0.1988\n",
      "Epoch 20/100\n",
      "92s - loss: 0.1988\n",
      "Epoch 21/100\n",
      "92s - loss: 0.1988\n",
      "Epoch 22/100\n",
      "92s - loss: 0.1987\n",
      "Epoch 23/100\n",
      "92s - loss: 0.1987\n",
      "Epoch 24/100\n",
      "92s - loss: 0.1987\n",
      "Epoch 25/100\n",
      "92s - loss: 0.1986\n",
      "Epoch 26/100\n",
      "92s - loss: 0.1986\n",
      "Epoch 27/100\n",
      "92s - loss: 0.1986\n",
      "Epoch 28/100\n",
      "92s - loss: 0.1986\n",
      "Epoch 29/100\n",
      "92s - loss: 0.1985\n",
      "Epoch 30/100\n",
      "92s - loss: 0.1985\n",
      "Epoch 31/100\n",
      "92s - loss: 0.1985\n",
      "Epoch 32/100\n",
      "92s - loss: 0.1985\n",
      "Epoch 33/100\n",
      "92s - loss: 0.1985\n",
      "Epoch 34/100\n",
      "92s - loss: 0.1985\n",
      "Epoch 35/100\n",
      "92s - loss: 0.1985\n",
      "Epoch 36/100\n",
      "92s - loss: 0.1984\n",
      "Epoch 37/100\n",
      "92s - loss: 0.1984\n",
      "Epoch 38/100\n",
      "92s - loss: 0.1984\n",
      "Epoch 39/100\n",
      "92s - loss: 0.1984\n",
      "Epoch 40/100\n",
      "92s - loss: 0.1984\n",
      "Epoch 41/100\n",
      "92s - loss: 0.1984\n",
      "Epoch 42/100\n",
      "92s - loss: 0.1984\n",
      "Epoch 43/100\n",
      "92s - loss: 0.1984\n",
      "Epoch 44/100\n",
      "92s - loss: 0.1984\n",
      "Epoch 45/100\n",
      "92s - loss: 0.1983\n",
      "Epoch 46/100\n",
      "92s - loss: 0.1983\n",
      "Epoch 47/100\n",
      "92s - loss: 0.1983\n",
      "Epoch 48/100\n",
      "92s - loss: 0.1983\n",
      "Epoch 49/100\n",
      "92s - loss: 0.1983\n",
      "Epoch 50/100\n",
      "92s - loss: 0.1983\n",
      "Epoch 51/100\n",
      "92s - loss: 0.1983\n",
      "Epoch 52/100\n",
      "92s - loss: 0.1983\n",
      "Epoch 53/100\n",
      "92s - loss: 0.1983\n",
      "Epoch 54/100\n",
      "92s - loss: 0.1983\n",
      "Epoch 55/100\n",
      "92s - loss: 0.1983\n",
      "Epoch 56/100\n",
      "92s - loss: 0.1983\n",
      "Epoch 57/100\n",
      "92s - loss: 0.1983\n",
      "Epoch 58/100\n",
      "92s - loss: 0.1983\n",
      "Epoch 59/100\n",
      "92s - loss: 0.1983\n",
      "Epoch 60/100\n",
      "92s - loss: 0.1983\n",
      "Epoch 61/100\n",
      "92s - loss: 0.1983\n",
      "Epoch 62/100\n",
      "92s - loss: 0.1982\n",
      "Epoch 63/100\n",
      "92s - loss: 0.1982\n",
      "Epoch 64/100\n",
      "92s - loss: 0.1982\n",
      "Epoch 65/100\n",
      "92s - loss: 0.1982\n",
      "Epoch 66/100\n",
      "92s - loss: 0.1982\n",
      "Epoch 67/100\n",
      "92s - loss: 0.1982\n",
      "Epoch 68/100\n",
      "92s - loss: 0.1982\n",
      "Epoch 69/100\n",
      "92s - loss: 0.1982\n",
      "Epoch 70/100\n",
      "92s - loss: 0.1982\n",
      "Epoch 71/100\n",
      "92s - loss: 0.1982\n",
      "Epoch 72/100\n",
      "92s - loss: 0.1982\n",
      "Epoch 73/100\n",
      "92s - loss: 0.1982\n",
      "Epoch 74/100\n",
      "92s - loss: 0.1982\n",
      "Epoch 75/100\n",
      "92s - loss: 0.1982\n",
      "Epoch 76/100\n",
      "92s - loss: 0.1982\n",
      "Epoch 77/100\n",
      "92s - loss: 0.1982\n",
      "Epoch 78/100\n",
      "92s - loss: 0.1982\n",
      "Epoch 79/100\n",
      "92s - loss: 0.1982\n",
      "Epoch 80/100\n",
      "92s - loss: 0.1982\n",
      "Epoch 81/100\n",
      "92s - loss: 0.1982\n",
      "Epoch 82/100\n",
      "92s - loss: 0.1982\n",
      "Epoch 83/100\n",
      "92s - loss: 0.1982\n",
      "Epoch 84/100\n",
      "92s - loss: 0.1982\n",
      "Epoch 85/100\n",
      "92s - loss: 0.1982\n",
      "Epoch 86/100\n",
      "91s - loss: 0.1982\n",
      "Epoch 87/100\n",
      "91s - loss: 0.1981\n",
      "Epoch 88/100\n",
      "91s - loss: 0.1981\n",
      "Epoch 89/100\n",
      "91s - loss: 0.1981\n",
      "Epoch 90/100\n",
      "91s - loss: 0.1981\n",
      "Epoch 91/100\n",
      "91s - loss: 0.1981\n",
      "Epoch 92/100\n",
      "91s - loss: 0.1981\n",
      "Epoch 93/100\n",
      "91s - loss: 0.1981\n",
      "Epoch 94/100\n",
      "91s - loss: 0.1981\n",
      "Epoch 95/100\n",
      "91s - loss: 0.1982\n",
      "Epoch 96/100\n",
      "91s - loss: 0.1981\n",
      "Epoch 97/100\n",
      "91s - loss: 0.1981\n",
      "Epoch 98/100\n",
      "91s - loss: 0.1981\n",
      "Epoch 99/100\n",
      "91s - loss: 0.1981\n",
      "Epoch 100/100\n",
      "91s - loss: 0.1981\n",
      "model fit finished\n",
      "model predict finished\n",
      "Epoch 1/100\n",
      "92s - loss: 0.2072\n",
      "Epoch 2/100\n",
      "92s - loss: 0.2017\n",
      "Epoch 3/100\n",
      "91s - loss: 0.2006\n",
      "Epoch 4/100\n",
      "92s - loss: 0.2000\n",
      "Epoch 5/100\n",
      "91s - loss: 0.1996\n",
      "Epoch 6/100\n",
      "91s - loss: 0.1992\n",
      "Epoch 7/100\n",
      "91s - loss: 0.1990\n",
      "Epoch 8/100\n",
      "91s - loss: 0.1988\n",
      "Epoch 9/100\n",
      "91s - loss: 0.1986\n",
      "Epoch 10/100\n",
      "92s - loss: 0.1985\n",
      "Epoch 11/100\n",
      "94s - loss: 0.1984\n",
      "Epoch 12/100\n",
      "94s - loss: 0.1983\n",
      "Epoch 13/100\n",
      "93s - loss: 0.1983\n",
      "Epoch 14/100\n",
      "93s - loss: 0.1982\n",
      "Epoch 15/100\n",
      "95s - loss: 0.1981\n",
      "Epoch 16/100\n",
      "94s - loss: 0.1981\n",
      "Epoch 17/100\n",
      "95s - loss: 0.1981\n",
      "Epoch 18/100\n",
      "96s - loss: 0.1980\n",
      "Epoch 19/100\n",
      "93s - loss: 0.1980\n",
      "Epoch 20/100\n",
      "95s - loss: 0.1979\n",
      "Epoch 21/100\n",
      "94s - loss: 0.1979\n",
      "Epoch 22/100\n",
      "94s - loss: 0.1979\n",
      "Epoch 23/100\n",
      "93s - loss: 0.1978\n",
      "Epoch 24/100\n",
      "93s - loss: 0.1978\n",
      "Epoch 25/100\n",
      "94s - loss: 0.1978\n",
      "Epoch 26/100\n",
      "94s - loss: 0.1978\n",
      "Epoch 27/100\n",
      "96s - loss: 0.1978\n",
      "Epoch 28/100\n",
      "95s - loss: 0.1977\n",
      "Epoch 29/100\n",
      "95s - loss: 0.1977\n",
      "Epoch 30/100\n",
      "94s - loss: 0.1977\n",
      "Epoch 31/100\n",
      "93s - loss: 0.1977\n",
      "Epoch 32/100\n",
      "93s - loss: 0.1977\n",
      "Epoch 33/100\n",
      "92s - loss: 0.1976\n",
      "Epoch 34/100\n",
      "92s - loss: 0.1976\n",
      "Epoch 35/100\n",
      "92s - loss: 0.1976\n",
      "Epoch 36/100\n",
      "92s - loss: 0.1976\n",
      "Epoch 37/100\n",
      "92s - loss: 0.1976\n",
      "Epoch 38/100\n",
      "92s - loss: 0.1976\n",
      "Epoch 39/100\n",
      "92s - loss: 0.1976\n",
      "Epoch 40/100\n",
      "92s - loss: 0.1976\n",
      "Epoch 41/100\n",
      "93s - loss: 0.1975\n",
      "Epoch 42/100\n",
      "92s - loss: 0.1975\n",
      "Epoch 43/100\n",
      "92s - loss: 0.1975\n",
      "Epoch 44/100\n",
      "93s - loss: 0.1975\n",
      "Epoch 45/100\n",
      "92s - loss: 0.1975\n",
      "Epoch 46/100\n",
      "92s - loss: 0.1975\n",
      "Epoch 47/100\n",
      "92s - loss: 0.1975\n",
      "Epoch 48/100\n",
      "92s - loss: 0.1975\n",
      "Epoch 49/100\n",
      "92s - loss: 0.1975\n",
      "Epoch 50/100\n",
      "92s - loss: 0.1975\n",
      "Epoch 51/100\n",
      "93s - loss: 0.1975\n",
      "Epoch 52/100\n",
      "92s - loss: 0.1974\n",
      "Epoch 53/100\n",
      "92s - loss: 0.1974\n",
      "Epoch 54/100\n",
      "92s - loss: 0.1974\n",
      "Epoch 55/100\n",
      "93s - loss: 0.1974\n",
      "Epoch 56/100\n",
      "92s - loss: 0.1974\n",
      "Epoch 57/100\n",
      "92s - loss: 0.1974\n",
      "Epoch 58/100\n",
      "92s - loss: 0.1974\n",
      "Epoch 59/100\n",
      "92s - loss: 0.1974\n",
      "Epoch 60/100\n",
      "92s - loss: 0.1974\n",
      "Epoch 61/100\n",
      "92s - loss: 0.1974\n",
      "Epoch 62/100\n",
      "92s - loss: 0.1974\n",
      "Epoch 63/100\n",
      "92s - loss: 0.1974\n",
      "Epoch 64/100\n",
      "92s - loss: 0.1974\n",
      "Epoch 65/100\n",
      "92s - loss: 0.1974\n",
      "Epoch 66/100\n",
      "92s - loss: 0.1974\n",
      "Epoch 67/100\n",
      "92s - loss: 0.1974\n",
      "Epoch 68/100\n",
      "92s - loss: 0.1974\n",
      "Epoch 69/100\n",
      "92s - loss: 0.1973\n",
      "Epoch 70/100\n",
      "92s - loss: 0.1974\n",
      "Epoch 71/100\n",
      "91s - loss: 0.1974\n",
      "Epoch 72/100\n",
      "91s - loss: 0.1973\n",
      "Epoch 73/100\n",
      "91s - loss: 0.1973\n",
      "Epoch 74/100\n",
      "92s - loss: 0.1973\n",
      "Epoch 75/100\n",
      "92s - loss: 0.1973\n",
      "Epoch 76/100\n",
      "92s - loss: 0.1973\n",
      "Epoch 77/100\n",
      "91s - loss: 0.1973\n",
      "Epoch 78/100\n",
      "92s - loss: 0.1973\n",
      "Epoch 79/100\n",
      "91s - loss: 0.1973\n",
      "Epoch 80/100\n",
      "93s - loss: 0.1973\n",
      "Epoch 81/100\n",
      "93s - loss: 0.1973\n",
      "Epoch 82/100\n",
      "93s - loss: 0.1973\n",
      "Epoch 83/100\n",
      "93s - loss: 0.1973\n",
      "Epoch 84/100\n",
      "93s - loss: 0.1973\n",
      "Epoch 85/100\n",
      "93s - loss: 0.1973\n",
      "Epoch 86/100\n",
      "94s - loss: 0.1973\n",
      "Epoch 87/100\n",
      "93s - loss: 0.1973\n",
      "Epoch 88/100\n",
      "94s - loss: 0.1973\n",
      "Epoch 89/100\n",
      "93s - loss: 0.1973\n",
      "Epoch 90/100\n",
      "96s - loss: 0.1973\n",
      "Epoch 91/100\n",
      "92s - loss: 0.1973\n",
      "Epoch 92/100\n",
      "92s - loss: 0.1973\n",
      "Epoch 93/100\n",
      "92s - loss: 0.1973\n",
      "Epoch 94/100\n",
      "93s - loss: 0.1973\n",
      "Epoch 95/100\n",
      "91s - loss: 0.1973\n",
      "Epoch 96/100\n",
      "92s - loss: 0.1973\n",
      "Epoch 97/100\n",
      "92s - loss: 0.1973\n",
      "Epoch 98/100\n",
      "93s - loss: 0.1973\n",
      "Epoch 99/100\n",
      "92s - loss: 0.1973\n",
      "Epoch 100/100\n",
      "92s - loss: 0.1973\n",
      "model fit finished\n",
      "model predict finished\n",
      "Epoch 1/100\n",
      "93s - loss: 0.2093\n",
      "Epoch 2/100\n",
      "93s - loss: 0.2037\n",
      "Epoch 3/100\n",
      "93s - loss: 0.2024\n",
      "Epoch 4/100\n",
      "93s - loss: 0.2017\n",
      "Epoch 5/100\n",
      "93s - loss: 0.2012\n",
      "Epoch 6/100\n",
      "93s - loss: 0.2009\n",
      "Epoch 7/100\n",
      "95s - loss: 0.2007\n",
      "Epoch 8/100\n",
      "94s - loss: 0.2005\n",
      "Epoch 9/100\n",
      "93s - loss: 0.2003\n",
      "Epoch 10/100\n",
      "94s - loss: 0.2002\n",
      "Epoch 11/100\n",
      "94s - loss: 0.2001\n",
      "Epoch 12/100\n",
      "94s - loss: 0.2000\n",
      "Epoch 13/100\n",
      "94s - loss: 0.1999\n",
      "Epoch 14/100\n",
      "94s - loss: 0.1998\n",
      "Epoch 15/100\n",
      "94s - loss: 0.1998\n",
      "Epoch 16/100\n",
      "94s - loss: 0.1997\n",
      "Epoch 17/100\n",
      "95s - loss: 0.1996\n",
      "Epoch 18/100\n",
      "96s - loss: 0.1996\n",
      "Epoch 19/100\n",
      "95s - loss: 0.1995\n",
      "Epoch 20/100\n",
      "95s - loss: 0.1995\n",
      "Epoch 21/100\n",
      "95s - loss: 0.1995\n",
      "Epoch 22/100\n",
      "95s - loss: 0.1994\n",
      "Epoch 23/100\n",
      "97s - loss: 0.1994\n",
      "Epoch 24/100\n",
      "94s - loss: 0.1994\n",
      "Epoch 25/100\n",
      "94s - loss: 0.1993\n",
      "Epoch 26/100\n",
      "94s - loss: 0.1993\n",
      "Epoch 27/100\n",
      "96s - loss: 0.1993\n",
      "Epoch 28/100\n",
      "95s - loss: 0.1993\n",
      "Epoch 29/100\n",
      "94s - loss: 0.1992\n",
      "Epoch 30/100\n",
      "96s - loss: 0.1992\n",
      "Epoch 31/100\n",
      "96s - loss: 0.1992\n",
      "Epoch 32/100\n",
      "95s - loss: 0.1991\n",
      "Epoch 33/100\n",
      "95s - loss: 0.1991\n",
      "Epoch 34/100\n",
      "97s - loss: 0.1991\n",
      "Epoch 35/100\n",
      "97s - loss: 0.1991\n",
      "Epoch 36/100\n",
      "97s - loss: 0.1990\n",
      "Epoch 37/100\n",
      "94s - loss: 0.1990\n",
      "Epoch 38/100\n",
      "97s - loss: 0.1990\n",
      "Epoch 39/100\n",
      "96s - loss: 0.1990\n",
      "Epoch 40/100\n",
      "95s - loss: 0.1990\n",
      "Epoch 41/100\n",
      "95s - loss: 0.1990\n",
      "Epoch 42/100\n",
      "95s - loss: 0.1989\n",
      "Epoch 43/100\n",
      "95s - loss: 0.1989\n",
      "Epoch 44/100\n",
      "96s - loss: 0.1989\n",
      "Epoch 45/100\n",
      "111s - loss: 0.1989\n",
      "Epoch 46/100\n",
      "103s - loss: 0.1989\n",
      "Epoch 47/100\n",
      "103s - loss: 0.1988\n",
      "Epoch 48/100\n",
      "94s - loss: 0.1988\n",
      "Epoch 49/100\n",
      "95s - loss: 0.1988\n",
      "Epoch 50/100\n",
      "95s - loss: 0.1989\n",
      "Epoch 51/100\n",
      "95s - loss: 0.1988\n",
      "Epoch 52/100\n",
      "95s - loss: 0.1989\n",
      "Epoch 53/100\n",
      "96s - loss: 0.1988\n",
      "Epoch 54/100\n",
      "95s - loss: 0.1988\n",
      "Epoch 55/100\n",
      "95s - loss: 0.1988\n",
      "Epoch 56/100\n",
      "95s - loss: 0.1988\n",
      "Epoch 57/100\n",
      "95s - loss: 0.1987\n",
      "Epoch 58/100\n",
      "95s - loss: 0.1988\n",
      "Epoch 59/100\n",
      "94s - loss: 0.1988\n",
      "Epoch 60/100\n",
      "94s - loss: 0.1987\n",
      "Epoch 61/100\n",
      "94s - loss: 0.1988\n",
      "Epoch 62/100\n",
      "94s - loss: 0.1988\n",
      "Epoch 63/100\n",
      "94s - loss: 0.1987\n",
      "Epoch 64/100\n",
      "94s - loss: 0.1987\n",
      "Epoch 65/100\n",
      "96s - loss: 0.1987\n",
      "Epoch 66/100\n",
      "95s - loss: 0.1987\n",
      "Epoch 67/100\n",
      "96s - loss: 0.1987\n",
      "Epoch 68/100\n",
      "97s - loss: 0.1987\n",
      "Epoch 69/100\n",
      "95s - loss: 0.1987\n",
      "Epoch 70/100\n",
      "94s - loss: 0.1987\n",
      "Epoch 71/100\n",
      "95s - loss: 0.1986\n",
      "Epoch 72/100\n",
      "95s - loss: 0.1986\n",
      "Epoch 73/100\n",
      "96s - loss: 0.1987\n",
      "Epoch 74/100\n",
      "96s - loss: 0.1988\n",
      "Epoch 75/100\n",
      "94s - loss: 0.1987\n",
      "Epoch 76/100\n",
      "93s - loss: 0.1988\n",
      "Epoch 77/100\n",
      "94s - loss: 0.1987\n",
      "Epoch 78/100\n",
      "93s - loss: 0.1987\n",
      "Epoch 79/100\n",
      "94s - loss: 0.1986\n",
      "Epoch 80/100\n",
      "94s - loss: 0.1986\n",
      "Epoch 81/100\n",
      "94s - loss: 0.1986\n",
      "Epoch 82/100\n",
      "94s - loss: 0.1986\n",
      "Epoch 83/100\n",
      "93s - loss: 0.1986\n",
      "Epoch 84/100\n",
      "94s - loss: 0.1986\n",
      "Epoch 85/100\n",
      "93s - loss: 0.1986\n",
      "Epoch 86/100\n",
      "94s - loss: 0.1986\n",
      "Epoch 87/100\n",
      "94s - loss: 0.1987\n",
      "Epoch 88/100\n",
      "93s - loss: 0.1986\n",
      "Epoch 89/100\n",
      "94s - loss: 0.1986\n",
      "Epoch 90/100\n",
      "94s - loss: 0.1986\n",
      "Epoch 91/100\n",
      "93s - loss: 0.1986\n",
      "Epoch 92/100\n",
      "93s - loss: 0.1986\n",
      "Epoch 93/100\n",
      "93s - loss: 0.1986\n",
      "Epoch 94/100\n",
      "93s - loss: 0.1987\n",
      "Epoch 95/100\n",
      "93s - loss: 0.1987\n",
      "Epoch 96/100\n",
      "93s - loss: 0.1986\n",
      "Epoch 97/100\n",
      "93s - loss: 0.1986\n",
      "Epoch 98/100\n",
      "93s - loss: 0.1986\n",
      "Epoch 99/100\n",
      "93s - loss: 0.1986\n",
      "Epoch 100/100\n",
      "93s - loss: 0.1986\n",
      "model fit finished\n",
      "model predict finished\n",
      "Epoch 1/100\n",
      "108s - loss: 0.2066\n",
      "Epoch 2/100\n",
      "108s - loss: 0.2016\n",
      "Epoch 3/100\n",
      "108s - loss: 0.2002\n",
      "Epoch 4/100\n",
      "108s - loss: 0.1995\n",
      "Epoch 5/100\n",
      "108s - loss: 0.1992\n",
      "Epoch 6/100\n",
      "108s - loss: 0.1989\n",
      "Epoch 7/100\n",
      "108s - loss: 0.1987\n",
      "Epoch 8/100\n",
      "108s - loss: 0.1986\n",
      "Epoch 9/100\n",
      "108s - loss: 0.1984\n",
      "Epoch 10/100\n",
      "108s - loss: 0.1983\n",
      "Epoch 11/100\n",
      "108s - loss: 0.1982\n",
      "Epoch 12/100\n",
      "108s - loss: 0.1981\n",
      "Epoch 13/100\n",
      "108s - loss: 0.1981\n",
      "Epoch 14/100\n",
      "108s - loss: 0.1980\n",
      "Epoch 15/100\n",
      "108s - loss: 0.1979\n",
      "Epoch 16/100\n",
      "108s - loss: 0.1979\n",
      "Epoch 17/100\n",
      "108s - loss: 0.1978\n",
      "Epoch 18/100\n",
      "108s - loss: 0.1978\n",
      "Epoch 19/100\n",
      "108s - loss: 0.1977\n",
      "Epoch 20/100\n",
      "108s - loss: 0.1977\n",
      "Epoch 21/100\n",
      "108s - loss: 0.1977\n",
      "Epoch 22/100\n",
      "108s - loss: 0.1976\n",
      "Epoch 23/100\n",
      "108s - loss: 0.1976\n",
      "Epoch 24/100\n",
      "108s - loss: 0.1976\n",
      "Epoch 25/100\n",
      "108s - loss: 0.1975\n",
      "Epoch 26/100\n",
      "108s - loss: 0.1975\n",
      "Epoch 27/100\n",
      "108s - loss: 0.1975\n",
      "Epoch 28/100\n",
      "108s - loss: 0.1975\n",
      "Epoch 29/100\n",
      "108s - loss: 0.1974\n",
      "Epoch 30/100\n",
      "107s - loss: 0.1974\n",
      "Epoch 31/100\n",
      "107s - loss: 0.1974\n",
      "Epoch 32/100\n",
      "108s - loss: 0.1974\n",
      "Epoch 33/100\n",
      "108s - loss: 0.1974\n",
      "Epoch 34/100\n",
      "108s - loss: 0.1973\n",
      "Epoch 35/100\n",
      "108s - loss: 0.1973\n",
      "Epoch 36/100\n",
      "108s - loss: 0.1973\n",
      "Epoch 37/100\n",
      "109s - loss: 0.1973\n",
      "Epoch 38/100\n",
      "108s - loss: 0.1973\n",
      "Epoch 39/100\n",
      "107s - loss: 0.1973\n",
      "Epoch 40/100\n",
      "107s - loss: 0.1973\n",
      "Epoch 41/100\n",
      "114s - loss: 0.1972\n",
      "Epoch 42/100\n",
      "117s - loss: 0.1972\n",
      "Epoch 43/100\n",
      "117s - loss: 0.1972\n",
      "Epoch 44/100\n",
      "109s - loss: 0.1972\n",
      "Epoch 45/100\n",
      "108s - loss: 0.1972\n",
      "Epoch 46/100\n",
      "108s - loss: 0.1972\n",
      "Epoch 47/100\n",
      "108s - loss: 0.1972\n",
      "Epoch 48/100\n",
      "108s - loss: 0.1972\n",
      "Epoch 49/100\n",
      "109s - loss: 0.1972\n",
      "Epoch 50/100\n",
      "119s - loss: 0.1971\n",
      "Epoch 51/100\n",
      "114s - loss: 0.1972\n",
      "Epoch 52/100\n",
      "108s - loss: 0.1972\n",
      "Epoch 53/100\n",
      "111s - loss: 0.1971\n",
      "Epoch 54/100\n",
      "111s - loss: 0.1971\n",
      "Epoch 55/100\n",
      "109s - loss: 0.1971\n",
      "Epoch 56/100\n",
      "112s - loss: 0.1971\n",
      "Epoch 57/100\n",
      "115s - loss: 0.1971\n",
      "Epoch 58/100\n",
      "116s - loss: 0.1971\n",
      "Epoch 59/100\n",
      "111s - loss: 0.1971\n",
      "Epoch 60/100\n",
      "111s - loss: 0.1971\n",
      "Epoch 61/100\n",
      "110s - loss: 0.1971\n",
      "Epoch 62/100\n",
      "114s - loss: 0.1971\n",
      "Epoch 63/100\n",
      "120s - loss: 0.1971\n",
      "Epoch 64/100\n",
      "114s - loss: 0.1971\n",
      "Epoch 65/100\n",
      "112s - loss: 0.1971\n",
      "Epoch 66/100\n",
      "108s - loss: 0.1971\n",
      "Epoch 67/100\n",
      "108s - loss: 0.1971\n",
      "Epoch 68/100\n",
      "108s - loss: 0.1971\n",
      "Epoch 69/100\n",
      "108s - loss: 0.1971\n",
      "Epoch 70/100\n",
      "108s - loss: 0.1971\n",
      "Epoch 71/100\n",
      "108s - loss: 0.1970\n",
      "Epoch 72/100\n",
      "108s - loss: 0.1970\n",
      "Epoch 73/100\n",
      "108s - loss: 0.1970\n",
      "Epoch 74/100\n",
      "108s - loss: 0.1970\n",
      "Epoch 75/100\n",
      "108s - loss: 0.1970\n",
      "Epoch 76/100\n",
      "108s - loss: 0.1970\n",
      "Epoch 77/100\n",
      "108s - loss: 0.1970\n",
      "Epoch 78/100\n",
      "108s - loss: 0.1970\n",
      "Epoch 79/100\n",
      "108s - loss: 0.1970\n",
      "Epoch 80/100\n",
      "108s - loss: 0.1970\n",
      "Epoch 81/100\n",
      "108s - loss: 0.1970\n",
      "Epoch 82/100\n",
      "108s - loss: 0.1970\n",
      "Epoch 83/100\n",
      "108s - loss: 0.1970\n",
      "Epoch 84/100\n",
      "108s - loss: 0.1970\n",
      "Epoch 85/100\n",
      "108s - loss: 0.1970\n",
      "Epoch 86/100\n",
      "108s - loss: 0.1970\n",
      "Epoch 87/100\n",
      "108s - loss: 0.1970\n",
      "Epoch 88/100\n",
      "108s - loss: 0.1970\n",
      "Epoch 89/100\n",
      "108s - loss: 0.1970\n",
      "Epoch 90/100\n",
      "108s - loss: 0.1970\n",
      "Epoch 91/100\n",
      "108s - loss: 0.1970\n",
      "Epoch 92/100\n",
      "109s - loss: 0.1970\n",
      "Epoch 93/100\n",
      "108s - loss: 0.1970\n",
      "Epoch 94/100\n",
      "108s - loss: 0.1970\n",
      "Epoch 95/100\n",
      "108s - loss: 0.1970\n",
      "Epoch 96/100\n",
      "108s - loss: 0.1970\n",
      "Epoch 97/100\n",
      "108s - loss: 0.1970\n",
      "Epoch 98/100\n",
      "108s - loss: 0.1970\n",
      "Epoch 99/100\n",
      "108s - loss: 0.1970\n",
      "Epoch 100/100\n",
      "108s - loss: 0.1970\n",
      "model fit finished\n",
      "model predict finished\n"
     ]
    }
   ],
   "source": [
    "for train_indices, test_indices in k_fold:\n",
    "\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=38, init='normal', activation='relu',W_regularizer=l2(0.00000001)))\n",
    "    # model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, init='normal', activation='relu'))\n",
    "    # model.add(Dropout(0.3))\n",
    "    model.add(Dense(32, init='normal', activation='relu'))\n",
    "    # model.add(Dropout(0.3))\n",
    "    model.add(Dense(8, init='normal', activation='relu'))\n",
    "    # model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, init='normal',activation = 'linear'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    # fit model\n",
    "    model.fit(train_dataset_10_normalize.loc[train_indices,predictors_10].as_matrix(),\n",
    "              train_dataset_10_normalize.loc[train_indices,'target'].as_matrix(),\n",
    "              nb_epoch=100, shuffle = True, batch_size=128,validation_split = 0,verbose = 2)\n",
    "    \n",
    "    print 'model fit finished'\n",
    "    stack_submission_nn_10.loc[test_indices] = model.predict(train_dataset_10_normalize.\\\n",
    "                                                                       loc[test_indices,predictors_10].as_matrix(),\n",
    "                                                         batch_size=128, verbose=2)\n",
    "    print 'model predict finished'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.470119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.667063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.882208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.318728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.153247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    predict\n",
       "0  3.470119\n",
       "1  2.667063\n",
       "2  1.882208\n",
       "3  3.318728\n",
       "4  4.153247"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_submission_nn_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack_submission_nn_10.to_pickle('stack_train_nn_10.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### over model stacking traing prepare\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['agen_for_log_de', 'ruta_for_log_de', 'cliente_for_log_de',\n",
       "       'producto_for_log_de', 'agen_ruta_for_log_de',\n",
       "       'agen_cliente_for_log_de', 'agen_producto_for_log_de',\n",
       "       'ruta_cliente_for_log_de', 'ruta_producto_for_log_de',\n",
       "       'cliente_producto_for_log_de', 'cliente_for_log_sum', 'corr',\n",
       "       't_min_1', 't_min_2', 't_min_3', 't_min_4', 't_min_5', 't1_min_t2',\n",
       "       't1_min_t3', 't1_min_t4', 't1_min_t5', 't2_min_t3', 't2_min_t4',\n",
       "       't2_min_t5', 't3_min_t4', 't3_min_t5', 't4_min_t5', 'LR_prod',\n",
       "       'LR_prod_corr', 't_m_5_cum', 't_m_4_cum', 't_m_3_cum', 't_m_2_cum',\n",
       "       't_m_1_cum', 'NombreCliente', 'weight', 'weight_per_piece',\n",
       "       'pieces', 'target'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_10_normalize.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3538385, 38)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_10_normalize.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_nn_time1 = train_dataset_10_normalize[predictors_10].copy()\n",
    "label_nn_time1 = train_dataset_10_normalize['target'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_nn_time1.fillna(-1,inplace = True)\n",
    "# train_nn_time1.fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_nn_time1 = train_nn_time1.as_matrix()\n",
    "label_nn_time1 = label_nn_time1.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dataset_10_normalize.fillna(-1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_nn_time1 = test_dataset_10_normalize.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "train_nn_time1, label_nn_time1 = shuffle(train_nn_time1, label_nn_time1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16614921 samples, validate on 4153731 samples\n",
      "Epoch 1/72\n",
      "99s - loss: 0.1997 - val_loss: 0.2002\n",
      "Epoch 2/72\n",
      "98s - loss: 0.1997 - val_loss: 0.1989\n",
      "Epoch 3/72\n",
      "98s - loss: 0.1997 - val_loss: 0.1985\n",
      "Epoch 4/72\n",
      "97s - loss: 0.1997 - val_loss: 0.1992\n",
      "Epoch 5/72\n",
      "97s - loss: 0.1997 - val_loss: 0.1989\n",
      "Epoch 6/72\n",
      "98s - loss: 0.1997 - val_loss: 0.1986\n",
      "Epoch 7/72\n",
      "97s - loss: 0.1997 - val_loss: 0.2002\n",
      "Epoch 8/72\n",
      "98s - loss: 0.1997 - val_loss: 0.1987\n",
      "Epoch 9/72\n",
      "99s - loss: 0.1996 - val_loss: 0.2000\n",
      "Epoch 10/72\n",
      "98s - loss: 0.1997 - val_loss: 0.2018\n",
      "Epoch 11/72\n",
      "97s - loss: 0.1997 - val_loss: 0.1992\n",
      "Epoch 12/72\n",
      "97s - loss: 0.1997 - val_loss: 0.1992\n",
      "Epoch 13/72\n",
      "97s - loss: 0.1997 - val_loss: 0.1991\n",
      "Epoch 14/72\n",
      "97s - loss: 0.1996 - val_loss: 0.2003\n",
      "Epoch 15/72\n",
      "100s - loss: 0.1996 - val_loss: 0.1986\n",
      "Epoch 16/72\n",
      "97s - loss: 0.1996 - val_loss: 0.1992\n",
      "Epoch 17/72\n",
      "97s - loss: 0.1996 - val_loss: 0.2000\n",
      "Epoch 18/72\n",
      "97s - loss: 0.1996 - val_loss: 0.1987\n",
      "Epoch 19/72\n",
      "97s - loss: 0.1997 - val_loss: 0.1984\n",
      "Epoch 20/72\n",
      "97s - loss: 0.1996 - val_loss: 0.1992\n",
      "Epoch 21/72\n",
      "97s - loss: 0.1997 - val_loss: 0.1987\n",
      "Epoch 22/72\n",
      "98s - loss: 0.1996 - val_loss: 0.1984\n",
      "Epoch 23/72\n",
      "98s - loss: 0.1997 - val_loss: 0.2001\n",
      "Epoch 24/72\n",
      "97s - loss: 0.1996 - val_loss: 0.1987\n",
      "Epoch 25/72\n",
      "97s - loss: 0.1996 - val_loss: 0.1990\n",
      "Epoch 26/72\n",
      "98s - loss: 0.1997 - val_loss: 0.1998\n",
      "Epoch 27/72\n",
      "98s - loss: 0.1996 - val_loss: 0.1990\n",
      "Epoch 28/72\n",
      "97s - loss: 0.1996 - val_loss: 0.1987\n",
      "Epoch 29/72\n",
      "98s - loss: 0.1996 - val_loss: 0.1987\n",
      "Epoch 30/72\n",
      "97s - loss: 0.1996 - val_loss: 0.1986\n",
      "Epoch 31/72\n",
      "98s - loss: 0.1996 - val_loss: 0.1996\n",
      "Epoch 32/72\n",
      "98s - loss: 0.1996 - val_loss: 0.1986\n",
      "Epoch 33/72\n",
      "98s - loss: 0.1996 - val_loss: 0.1987\n",
      "Epoch 34/72\n",
      "98s - loss: 0.1997 - val_loss: 0.1989\n",
      "Epoch 35/72\n",
      "98s - loss: 0.1996 - val_loss: 0.2005\n",
      "Epoch 36/72\n",
      "97s - loss: 0.1996 - val_loss: 0.1994\n",
      "Epoch 37/72\n",
      "97s - loss: 0.1996 - val_loss: 0.1992\n",
      "Epoch 38/72\n",
      "98s - loss: 0.1996 - val_loss: 0.2022\n",
      "Epoch 39/72\n",
      "97s - loss: 0.1996 - val_loss: 0.1995\n",
      "Epoch 40/72\n",
      "97s - loss: 0.1996 - val_loss: 0.1991\n",
      "Epoch 41/72\n",
      "97s - loss: 0.1996 - val_loss: 0.1995\n",
      "Epoch 42/72\n",
      "99s - loss: 0.1996 - val_loss: 0.1991\n",
      "Epoch 43/72\n",
      "98s - loss: 0.1996 - val_loss: 0.1994\n",
      "Epoch 44/72\n",
      "99s - loss: 0.1996 - val_loss: 0.1990\n",
      "Epoch 45/72\n",
      "98s - loss: 0.1996 - val_loss: 0.2003\n",
      "Epoch 46/72\n",
      "99s - loss: 0.1996 - val_loss: 0.1985\n",
      "Epoch 47/72\n",
      "98s - loss: 0.1996 - val_loss: 0.1990\n",
      "Epoch 48/72\n",
      "98s - loss: 0.1996 - val_loss: 0.1987\n",
      "Epoch 49/72\n",
      "99s - loss: 0.1996 - val_loss: 0.1984\n",
      "Epoch 50/72\n",
      "98s - loss: 0.1996 - val_loss: 0.1987\n",
      "Epoch 51/72\n",
      "98s - loss: 0.1996 - val_loss: 0.1994\n",
      "Epoch 52/72\n",
      "99s - loss: 0.1996 - val_loss: 0.1999\n",
      "Epoch 53/72\n",
      "100s - loss: 0.1996 - val_loss: 0.1997\n",
      "Epoch 54/72\n",
      "100s - loss: 0.1996 - val_loss: 0.1985\n",
      "Epoch 55/72\n",
      "103s - loss: 0.1996 - val_loss: 0.1992\n",
      "Epoch 56/72\n",
      "100s - loss: 0.1996 - val_loss: 0.1986\n",
      "Epoch 57/72\n",
      "99s - loss: 0.1996 - val_loss: 0.1989\n",
      "Epoch 58/72\n",
      "102s - loss: 0.1996 - val_loss: 0.1987\n",
      "Epoch 59/72\n",
      "100s - loss: 0.1996 - val_loss: 0.1985\n",
      "Epoch 60/72\n",
      "99s - loss: 0.1996 - val_loss: 0.1984\n",
      "Epoch 61/72\n",
      "98s - loss: 0.1996 - val_loss: 0.2011\n",
      "Epoch 62/72\n",
      "98s - loss: 0.1996 - val_loss: 0.1986\n",
      "Epoch 63/72\n",
      "96s - loss: 0.1996 - val_loss: 0.1994\n",
      "Epoch 64/72\n",
      "96s - loss: 0.1996 - val_loss: 0.1995\n",
      "Epoch 65/72\n",
      "95s - loss: 0.1996 - val_loss: 0.1989\n",
      "Epoch 66/72\n",
      "95s - loss: 0.1996 - val_loss: 0.1992\n",
      "Epoch 67/72\n",
      "95s - loss: 0.1996 - val_loss: 0.2048\n",
      "Epoch 68/72\n",
      "95s - loss: 0.1996 - val_loss: 0.1988\n",
      "Epoch 69/72\n",
      "95s - loss: 0.1996 - val_loss: 0.1992\n",
      "Epoch 70/72\n",
      "95s - loss: 0.1996 - val_loss: 0.2016\n",
      "Epoch 71/72\n",
      "95s - loss: 0.1996 - val_loss: 0.2000\n",
      "Epoch 72/72\n",
      "95s - loss: 0.1996 - val_loss: 0.1994\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-20fd7a5b3078>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m model.fit(train_nn_time1, label_nn_time1, nb_epoch=72, shuffle = True, \n\u001b[1;32m     17\u001b[0m           batch_size=128,validation_split = 0.2,verbose = 2)\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=38, init='normal', activation='relu',W_regularizer=l2(0.00000001)))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Dense(64, init='normal', activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Dense(32, init='normal', activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Dense(8, init='normal', activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Dense(1, init='normal',activation = 'linear'))\n",
    "# Compile model\n",
    "model = load_model('model_nn_10_after_l2reg.h5')\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "model.fit(train_nn_time1, label_nn_time1, nb_epoch=100, shuffle = True, \n",
    "          batch_size=128,validation_split = 0.2,verbose = 2)\n",
    "time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model_nn_10_after_l2reg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sumbission_nn_10 = model.predict(test_nn_time1, batch_size=128, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_nn_10_whole = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_nn_10_whole['id'] = train_pivot_56789_to_10['id'].copy()\n",
    "submission_nn_10_whole['predict'] = pd.DataFrame(sumbission_nn_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1569352</td>\n",
       "      <td>1.748155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6667200</td>\n",
       "      <td>3.628597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1592616</td>\n",
       "      <td>2.999023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3909690</td>\n",
       "      <td>4.208099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3659672</td>\n",
       "      <td>3.577081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id   predict\n",
       "0  1569352  1.748155\n",
       "1  6667200  3.628597\n",
       "2  1592616  2.999023\n",
       "3  3909690  4.208099\n",
       "4  3659672  3.577081"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_nn_10_whole.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('model_nn_10_after_l2reg.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple merge nn\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_xgboost.ipynb                   submission_10_new.csv\r\n",
      "3_prediction.ipynb                submission_11.csv\r\n",
      "4_keras_nn.ipynb                  submission_11_new.csv\r\n",
      "5_random_forest.ipynb             submission_nn_xgb\r\n",
      "6_random_forest.ipynb             submission_xgb_10.pickle\r\n",
      "agencia_for_cliente_producto.csv  submission_xgb_2.csv\r\n",
      "canal_for_cliente_producto.csv    submission_xgb.csv\r\n",
      "model_nn_10.h5                    submission_xgb_nn_10.pickle\r\n",
      "model_nn_10_whole.h5              submission_xgb_with_nn.csv\r\n",
      "\u001b[0m\u001b[01;34morigin\u001b[0m/                           train_pivot_3456_to_8.csv\r\n",
      "pivot_test.pickle                 train_pivot_56789_to_10_new.pickle\r\n",
      "pivot_train_with_nan.pickle       train_pivot_56789_to_10.pickle\r\n",
      "pivot_train_with_zero.pickle      train_pivot_6789_to_11_new.pickle\r\n",
      "preprocessed_products.csv         train_pivot_6789_to_11.pickle\r\n",
      "ruta_for_cliente_producto.csv     train_pivot_xgb_time1.csv\r\n",
      "submission_10.csv                 train_pivot_xgb_time2.csv\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1547831</td>\n",
       "      <td>4.406201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6825659</td>\n",
       "      <td>3.053817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5853787</td>\n",
       "      <td>2.684612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2316053</td>\n",
       "      <td>1.259826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>900676</td>\n",
       "      <td>2.301486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id   predict\n",
       "0  1547831  4.406201\n",
       "1  6825659  3.053817\n",
       "2  5853787  2.684612\n",
       "3  2316053  1.259826\n",
       "4   900676  2.301486"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_xgb_11 = pd.read_csv('submission_11_new.csv',index_col = 0)\n",
    "submission_xgb_11['predict'] = submission_xgb_11[['predict_' + str(i) for i in range(20)]].mean(axis=1)\n",
    "submission_xgb_11.drop(['predict_' + str(i) for i in range(20)],axis =1,inplace = True)\n",
    "submission_xgb_11.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.460866e+06\n",
       "mean     1.575306e+00\n",
       "std      7.042961e-01\n",
       "min     -5.776052e-01\n",
       "25%      1.066204e+00\n",
       "50%      1.410357e+00\n",
       "75%      1.900692e+00\n",
       "max      7.862914e+00\n",
       "Name: predict, dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_xgb_11['predict'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10517091807564763"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expm1(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_nn = pd.concat([submission_nn_10_whole,submission_xgb_11],axis = 0,copy = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6.999251e+06\n",
       "mean     1.583278e+00\n",
       "std      7.158656e-01\n",
       "min      7.535815e-05\n",
       "25%      1.066688e+00\n",
       "50%      1.416326e+00\n",
       "75%      1.915690e+00\n",
       "max      8.414549e+00\n",
       "Name: predict, dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = submission_nn[submission_nn['predict'] < 0].index\n",
    "submission_nn.loc[mask, 'predict'] = 0.001\n",
    "submission_nn['predict'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_nn['predict'] = submission_nn['predict'].apply(np.expm1)\n",
    "submission_nn.rename(columns = {'predict':'Demanda_uni_equil'},inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Demanda_uni_equil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1569352</td>\n",
       "      <td>4.743992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6667200</td>\n",
       "      <td>36.659952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1592616</td>\n",
       "      <td>19.065922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3909690</td>\n",
       "      <td>66.228609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3659672</td>\n",
       "      <td>34.768986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  Demanda_uni_equil\n",
       "0  1569352           4.743992\n",
       "1  6667200          36.659952\n",
       "2  1592616          19.065922\n",
       "3  3909690          66.228609\n",
       "4  3659672          34.768986"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_nn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_nn['Demanda_uni_equil'] = submission_nn['Demanda_uni_equil'].round(1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6.999251e+06\n",
       "mean     6.320197e+00\n",
       "std      1.891876e+01\n",
       "min      0.000000e+00\n",
       "25%      1.900000e+00\n",
       "50%      3.100000e+00\n",
       "75%      5.800000e+00\n",
       "max      4.511200e+03\n",
       "Name: Demanda_uni_equil, dtype: float64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_nn['Demanda_uni_equil'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_nn.to_csv('submission_nn_2.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-4.000000e-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = submission_nn_10[submission_nn_10['predict'] < 0].index\n",
    "submission_nn_10.loc[mask, 'predict'] = 0 \n",
    "submission_nn_10['predict'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.538385e+06\n",
       "mean     1.565618e+00\n",
       "std      6.791419e-01\n",
       "min      0.000000e+00\n",
       "25%      1.078582e+00\n",
       "50%      1.403452e+00\n",
       "75%      1.885645e+00\n",
       "max      1.081926e+01\n",
       "Name: predict, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:1: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "submission_nn_10.sort(['id'],inplace = True)\n",
    "submission_nn_10.reset_index(inplace = True,drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.246212</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.864159</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.587973</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.098800</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.758513</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    predict  id\n",
       "0  1.246212   2\n",
       "1  1.864159   7\n",
       "2  1.587973   8\n",
       "3  1.098800  11\n",
       "4  1.758513  13"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_nn_10.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try to do model stacking\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_xgboost.ipynb                   submission_10_new.csv\r\n",
      "3_prediction.ipynb                submission_11.csv\r\n",
      "4_keras_nn.ipynb                  submission_11_new.csv\r\n",
      "agencia_for_cliente_producto.csv  submission_xgb_2.csv\r\n",
      "canal_for_cliente_producto.csv    submission_xgb.csv\r\n",
      "model_nn_10.h5                    submission_xgb_with_nn.csv\r\n",
      "\u001b[0m\u001b[01;34morigin\u001b[0m/                           train_pivot_3456_to_8.csv\r\n",
      "pivot_test.pickle                 train_pivot_56789_to_10_new.pickle\r\n",
      "pivot_train_with_nan.pickle       train_pivot_56789_to_10.pickle\r\n",
      "pivot_train_with_zero.pickle      train_pivot_6789_to_11_new.pickle\r\n",
      "preprocessed_products.csv         train_pivot_6789_to_11.pickle\r\n",
      "ruta_for_cliente_producto.csv     train_pivot_xgb_time1.csv\r\n",
      "submission_10.csv                 train_pivot_xgb_time2.csv\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_xgb_10 = pd.read_csv('submission_10_new.csv',index_col = 0)\n",
    "submission_xgb_10['predict'] = submission_xgb_10[['predict_' + str(i) for i in range(20)]].mean(axis=1)\n",
    "submission_xgb_10.drop(['predict_' + str(i) for i in range(20)],axis =1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:1: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "submission_xgb_10.sort(['id'],inplace = True)\n",
    "submission_xgb_10.reset_index(inplace = True,drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1.179090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1.726247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1.560164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>1.080983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>1.802365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   predict\n",
       "0   2  1.179090\n",
       "1   7  1.726247\n",
       "2   8  1.560164\n",
       "3  11  1.080983\n",
       "4  13  1.802365"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_xgb_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_xgb_10['nn_predict'] = submission_nn_10['predict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_xgb_10['combine_predict'] =  submission_xgb_10['predict']*0.8 + submission_xgb_10['nn_predict'] *0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predict</th>\n",
       "      <th>nn_predict</th>\n",
       "      <th>combine_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1.179090</td>\n",
       "      <td>1.246212</td>\n",
       "      <td>1.192515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1.726247</td>\n",
       "      <td>1.864159</td>\n",
       "      <td>1.753829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1.560164</td>\n",
       "      <td>1.587973</td>\n",
       "      <td>1.565726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>1.080983</td>\n",
       "      <td>1.098800</td>\n",
       "      <td>1.084546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>1.802365</td>\n",
       "      <td>1.758513</td>\n",
       "      <td>1.793594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   predict  nn_predict  combine_predict\n",
       "0   2  1.179090    1.246212         1.192515\n",
       "1   7  1.726247    1.864159         1.753829\n",
       "2   8  1.560164    1.587973         1.565726\n",
       "3  11  1.080983    1.098800         1.084546\n",
       "4  13  1.802365    1.758513         1.793594"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_xgb_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>xgb_predict</th>\n",
       "      <th>nn_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1.179090</td>\n",
       "      <td>1.246212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1.726247</td>\n",
       "      <td>1.864159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1.560164</td>\n",
       "      <td>1.587973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>1.080983</td>\n",
       "      <td>1.098800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>1.802365</td>\n",
       "      <td>1.758513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  xgb_predict  nn_predict\n",
       "0   2     1.179090    1.246212\n",
       "1   7     1.726247    1.864159\n",
       "2   8     1.560164    1.587973\n",
       "3  11     1.080983    1.098800\n",
       "4  13     1.802365    1.758513"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_xgb_10.drop(['combine_predict'],axis =1, inplace = True)\n",
    "submission_xgb_10.rename(columns = {'predict': 'xgb_predict'},inplace = True)\n",
    "submission_xgb_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_xgb_10.to_pickle('submission_xgb_nn_10.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3538385, 4)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_xgb_10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_10 = submission_xgb_10[['id','combine_predict']].copy()\n",
    "submission_10['combine_predict'] = submission_10['combine_predict'].apply(np.expm1)\n",
    "submission_10.rename(columns = {'combine_predict':'Demanda_uni_equil'},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Demanda_uni_equil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2.295357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>4.776682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>3.786146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>1.958096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>5.011020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Demanda_uni_equil\n",
       "0   2           2.295357\n",
       "1   7           4.776682\n",
       "2   8           3.786146\n",
       "3  11           1.958096\n",
       "4  13           5.011020"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_xgb_11 = pd.read_csv('submission_11_new.csv',index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Demanda_uni_equil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1547831</td>\n",
       "      <td>80.957476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6825659</td>\n",
       "      <td>20.196086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5853787</td>\n",
       "      <td>13.652510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2316053</td>\n",
       "      <td>2.524808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>900676</td>\n",
       "      <td>8.989011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  Demanda_uni_equil\n",
       "0  1547831          80.957476\n",
       "1  6825659          20.196086\n",
       "2  5853787          13.652510\n",
       "3  2316053           2.524808\n",
       "4   900676           8.989011"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_xgb_11['Demanda_uni_equil'] = submission_xgb_11[['predict_' + str(i) for i in range(20)]].mean(axis=1)\n",
    "submission_xgb_11.drop(['predict_' + str(i) for i in range(20)],axis =1,inplace = True)\n",
    "submission_xgb_11['Demanda_uni_equil'] = submission_xgb_11['Demanda_uni_equil'].apply(np.expm1)\n",
    "submission_xgb_11.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Demanda_uni_equil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2.295357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>4.776682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>3.786146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>1.958096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>5.011020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Demanda_uni_equil\n",
       "0   2           2.295357\n",
       "1   7           4.776682\n",
       "2   8           3.786146\n",
       "3  11           1.958096\n",
       "4  13           5.011020"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_final  = pd.concat([submission_10,submission_xgb_11],axis = 0)\n",
    "submission_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_final['Demanda_uni_equil'] = submission_final['Demanda_uni_equil'].round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_final.to_csv('submission_nn_xgb',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
